{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DCCRN\n",
    "import torch\n",
    "from asteroid.data import DNSDataset\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import numpy as np\n",
    "from framework import ABF, MultiResolutionSTFTLoss, SPKDLoss, build_review_kd, ReviewKD\n",
    "import asteroid\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import config as cfg\n",
    "from tools_for_model import near_avg_index, max_index, min_index, Bar, cal_pesq, cal_stoi\n",
    "from dataloader import create_dataloader\n",
    "import inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DCCRN.DCCRN(rnn_units=cfg.rnn_units, masking_mode=cfg.masking_mode, use_clstm=cfg.use_clstm,\n",
    "                  kernel_num=cfg.kernel_num)\n",
    "#data_set =  DNSDataset(\"/root/NTH_student/Speech_Enhancement_new/asteroid/egs/dns_challenge/baseline/data\")\n",
    "train_dataset =  DNSDataset(\"/root/NTH_student/test_loader\")\n",
    "train_loader = create_dataloader(mode='train',dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo sample để input mode. cái này random đại thui\n",
    "# input_size = model.stft.weight.size(1)\n",
    "# tạo cái batch có n= 5 đi\n",
    "# input = torch.randn(64, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fd5fe1abd60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo list chứa các feature map do encoder output ra \n",
    "# dùng list vì lát nữa feature map của lstm với decoder bỏ vô đây luôn. ở đây demo cái encoder thui nha. \n",
    "feature_maps = []\n",
    "# Tạo hàm hook, hàm này sẽ thực thi khi encoder thực hiện forward.\n",
    "# output của encoder sẽ được append vào trong encoder_feature_map(một biến toàn cục)\n",
    "def encoder_hook(module, input, output):\n",
    "    feature_maps.append(output)\n",
    "# đăng kí forward hook. kiểu \"ê khi nào encoder thực hiện foward xong thì chạy hàm encoder_hook nha\"\n",
    "model.encoder[-1].register_forward_hook(encoder_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fd5fe1ac430>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decoder_hook(module, input, output):\n",
    "    feature_maps.append(output)\n",
    "\n",
    "model.decoder[-1].register_forward_hook(decoder_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enhance_hook(module, input, output):\n",
    "#     feature_maps.append(output)\n",
    "\n",
    "# model.enhance.register_forward_hook(enhance_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/600: [>.................................................] - ETA 0.8sau de\n"
     ]
    }
   ],
   "source": [
    "X,Y = 0,0\n",
    "i = 0\n",
    "for x,y,_ in Bar(train_loader):\n",
    "    if i == 1: break\n",
    "    X=x\n",
    "    Y=y\n",
    "    i += 1\n",
    "\n",
    "try :\n",
    "    model(X)\n",
    "    print('au de')\n",
    "except:\n",
    "    print('failed roihuhu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 4, 483])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[0].shape #[64, 256, 4, 483]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 256, 484])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = [32, 64, 128, 256, 256, 256]\n",
    "out_channels = [32, 64, 128, 256, 256, 256]\n",
    "\n",
    "# shapes = [1,4,8,16,32]\n",
    "# out_shapes = [1,4,8,16,32]\n",
    "shapes = [4,4,4]\n",
    "out_shapes = [4,4,4]\n",
    "abfs = nn.ModuleList()\n",
    "mid_channel = min(512, in_channels[-1])\n",
    "for idx, in_channel in enumerate(in_channels):\n",
    "    abfs.append(ABF(in_channel, mid_channel, out_channels[idx], idx < len(in_channels)-1))\n",
    "abfs = abfs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_features = model(X,is_feat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = student_features\n",
    "x = feature_maps[0] #encoder\n",
    "results = []\n",
    "out_features, res_features = abfs[0](x, out_shape=out_shapes[0])\n",
    "results.append(out_features)\n",
    "for abf, shape, out_shape in zip(abfs[1:], shapes[1:], out_shapes[1:]):\n",
    "        out_features, res_features = abf(x, res_features, shape, out_shape)\n",
    "results.insert(0, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-1.3222e+00, -8.9411e-01, -7.2742e-01, -2.8366e+00],\n",
       "           [-1.2539e+00,  2.8833e+00, -3.6291e-02,  6.6587e-01],\n",
       "           [ 8.1623e-02, -7.6165e+00, -2.3029e+00, -1.9873e+00],\n",
       "           [ 2.1454e-01,  6.7703e-01,  4.2594e-01,  2.0992e-01]],\n",
       " \n",
       "          [[ 2.1896e+00,  5.2855e+00, -1.5124e+00, -3.8074e+00],\n",
       "           [-6.6654e-01, -2.5278e+00, -1.2095e+00,  5.2766e+00],\n",
       "           [ 2.8943e-01,  3.7082e-01,  2.2154e+00, -2.0367e+00],\n",
       "           [ 1.3596e-02,  2.8615e-01,  4.1438e-01, -6.0898e-01]],\n",
       " \n",
       "          [[ 1.2320e+00,  6.2861e-01,  2.6034e+00, -4.9569e+00],\n",
       "           [ 8.7635e-01,  9.5193e-01,  1.1344e+00, -1.7390e+00],\n",
       "           [-1.2537e+00, -1.8615e+00, -5.2041e+00,  1.4772e+00],\n",
       "           [ 3.4433e-04,  3.1820e-01, -2.6376e-01, -5.7935e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.1556e-01, -2.9198e+00,  2.2692e+00,  3.3637e+00],\n",
       "           [-1.0380e+00, -1.0642e+00, -3.1786e+00,  3.5835e+00],\n",
       "           [ 4.7406e-01,  1.4743e+00,  5.4528e+00, -5.3188e+00],\n",
       "           [ 7.0392e-02,  1.3227e-01, -4.2768e-01, -5.8420e-01]],\n",
       " \n",
       "          [[ 9.9825e-01, -3.3562e-01, -5.2300e+00, -1.8447e+00],\n",
       "           [ 1.0392e+00, -9.4618e-02, -1.1777e+00, -3.8946e+00],\n",
       "           [ 3.0559e-01,  1.0466e+00, -6.5068e-01, -7.3082e+00],\n",
       "           [ 1.8534e-02,  3.0853e-01, -1.3677e-01, -1.4428e-01]],\n",
       " \n",
       "          [[ 7.8560e-01,  2.1166e+00, -4.2785e+00, -5.4939e+00],\n",
       "           [ 6.3460e-01, -3.8463e-01, -8.9780e-01, -7.0550e+00],\n",
       "           [-5.5299e-01, -2.4274e+00, -2.7991e-01,  3.2692e-01],\n",
       "           [ 2.1314e-01, -4.1515e-01,  2.9525e-01, -8.6263e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.2180e-01,  3.3458e-02,  1.1894e-01,  4.0107e-01],\n",
       "           [-3.0516e-01, -1.9952e-01,  2.3054e-01,  3.3786e-01],\n",
       "           [-3.3945e-01,  1.0237e-01, -5.2906e-02,  2.5754e-01],\n",
       "           [-7.2641e-02,  3.0224e-01,  4.0865e-01,  3.3274e-01]],\n",
       " \n",
       "          [[-2.6360e-02, -3.7952e-02, -1.0656e-01, -6.3847e-02],\n",
       "           [-6.4189e-02, -2.9300e-02, -1.3065e-01, -1.0150e-01],\n",
       "           [-6.6045e-02, -3.5327e-01, -2.3314e-01, -7.8469e-02],\n",
       "           [ 4.7625e-02, -1.4204e-01, -1.6845e-01,  1.5303e-02]],\n",
       " \n",
       "          [[ 3.8726e-02, -1.1387e-04, -2.3708e-01, -3.1169e-02],\n",
       "           [ 1.0750e-01,  7.4680e-04, -7.6151e-02,  1.8753e-01],\n",
       "           [ 1.8519e-01, -2.7478e-01, -3.3171e-01, -1.3936e-01],\n",
       "           [ 2.3909e-01,  7.7889e-02, -5.0061e-02,  2.1435e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.9285e-02,  6.5725e-02,  1.8499e-01,  1.9811e-01],\n",
       "           [-5.9103e-02,  4.0226e-02,  4.0275e-02,  1.2341e-01],\n",
       "           [-2.9721e-02, -1.0553e-01,  8.3744e-02,  2.5300e-02],\n",
       "           [-1.1691e-01, -2.0300e-02,  7.7536e-02,  1.1797e-01]],\n",
       " \n",
       "          [[ 1.0172e-01,  1.8497e-01,  1.9749e-01,  1.4143e-01],\n",
       "           [ 2.4265e-01,  1.2846e-01,  2.7145e-01,  3.7122e-01],\n",
       "           [ 2.2227e-01,  3.6444e-01,  4.4365e-01,  4.6662e-01],\n",
       "           [ 1.1351e-01,  1.7771e-01,  1.3646e-01,  3.5487e-01]],\n",
       " \n",
       "          [[ 2.2485e-01,  1.4623e-01,  1.6090e-01,  2.3001e-01],\n",
       "           [ 5.2099e-01,  2.2037e-01,  2.6076e-01,  2.7097e-01],\n",
       "           [ 3.0578e-01,  1.9540e-01,  1.5971e-01,  1.7898e-01],\n",
       "           [ 2.2954e-01,  1.1306e-01,  1.2371e-01,  1.1575e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1991e-02,  1.2357e-01, -2.0306e-01,  1.3819e+00],\n",
       "           [-1.5372e-01, -1.1328e-01,  9.0683e-01,  8.0509e-01],\n",
       "           [-3.7800e-01, -7.6050e-02, -2.3532e-03,  2.6345e-01],\n",
       "           [-7.9126e-02,  2.7098e-01,  3.8747e-01,  2.5667e-01]],\n",
       " \n",
       "          [[-2.3710e-02, -1.5242e-01,  8.4164e-02,  5.8429e-01],\n",
       "           [-1.2630e-01, -3.1261e-01, -6.5813e-01, -5.4553e-01],\n",
       "           [ 1.0541e-01,  1.3259e-01, -1.0292e-01,  2.2907e-01],\n",
       "           [ 2.5856e-02,  1.4328e-02,  1.1016e-01,  1.7197e-01]],\n",
       " \n",
       "          [[ 7.4370e-03,  2.2696e-01,  6.3758e-01, -6.6059e-02],\n",
       "           [-4.9918e-02, -4.7127e-01,  1.4344e+00,  2.4864e-01],\n",
       "           [ 9.6642e-02, -5.1823e-01, -4.8062e-01, -3.9214e-01],\n",
       "           [ 1.3749e-01,  1.8191e-02,  3.6350e-01,  1.0872e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0973e-01, -3.8371e-02, -1.2714e-02,  3.8361e-01],\n",
       "           [-2.6373e-02,  2.4109e-01, -3.0736e-01, -3.8503e-01],\n",
       "           [-5.5962e-02,  1.6414e-01, -2.0661e-01, -2.4817e-01],\n",
       "           [-1.8130e-01, -8.2846e-02,  1.7604e-01,  1.3075e-01]],\n",
       " \n",
       "          [[ 1.1215e-01,  8.8953e-02,  4.3119e-01,  5.4562e-01],\n",
       "           [ 1.2448e-01,  4.7059e-01, -2.0875e-02,  4.7713e-01],\n",
       "           [ 3.4243e-01,  3.2853e-01,  4.0485e-01,  4.7899e-02],\n",
       "           [ 1.5726e-01,  2.8677e-01,  2.1051e-01,  2.4980e-01]],\n",
       " \n",
       "          [[ 1.1125e-01,  3.8404e-01, -1.8973e-01,  4.7525e-01],\n",
       "           [ 4.9475e-01,  4.3319e-01,  4.2584e-01, -2.9482e-01],\n",
       "           [ 3.8360e-01,  2.4530e-01,  2.1485e-01,  5.4305e-01],\n",
       "           [ 3.0691e-01,  1.3708e-01,  8.5656e-02,  1.1717e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-4.4746e-02,  1.6923e-01,  1.8649e-02,  5.0630e-01],\n",
       "           [-3.5097e-01,  4.5385e-02,  9.6509e-02,  1.9097e-01],\n",
       "           [-4.1390e-01, -8.6055e-02,  6.6970e-02,  3.1030e-01],\n",
       "           [-1.0355e-01,  3.4914e-01,  3.2023e-01,  3.7570e-01]],\n",
       " \n",
       "          [[-1.0610e-01, -1.1474e-01, -8.9764e-02, -3.4118e-02],\n",
       "           [ 1.7075e-02, -4.8151e-02, -3.6962e-01,  3.0517e-01],\n",
       "           [-3.7728e-02, -4.7911e-02, -7.1543e-02, -2.0710e-02],\n",
       "           [ 3.1865e-02, -1.2838e-01, -2.7709e-02, -1.3403e-02]],\n",
       " \n",
       "          [[ 6.0223e-02, -4.8020e-01, -2.0198e-01,  4.9201e-02],\n",
       "           [ 4.2238e-02, -2.0675e-01, -5.8924e-02,  1.3298e-01],\n",
       "           [ 8.7872e-02, -7.7101e-02, -2.1477e-01, -1.4029e-01],\n",
       "           [ 2.3359e-01,  3.8889e-02,  2.0294e-02,  1.3585e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6448e-02, -3.8554e-02, -3.6265e-02,  6.3917e-03],\n",
       "           [-7.3882e-02,  1.1357e-01,  1.1269e-01, -3.0292e-02],\n",
       "           [-6.9363e-03,  5.4742e-03,  7.9649e-02,  4.6792e-02],\n",
       "           [-7.8897e-02, -4.6255e-02,  7.4142e-02,  1.0266e-01]],\n",
       " \n",
       "          [[ 1.3198e-01,  1.4140e-01,  1.0909e-01,  2.3392e-01],\n",
       "           [ 2.2194e-01,  2.8551e-01,  2.8744e-01,  4.1775e-01],\n",
       "           [ 2.0276e-01,  2.8913e-01,  1.3811e-01,  3.2194e-01],\n",
       "           [ 1.0078e-01,  1.9091e-01,  1.8272e-01,  2.5862e-01]],\n",
       " \n",
       "          [[ 2.0122e-01,  2.2941e-01,  1.6680e-01,  1.8113e-01],\n",
       "           [ 3.7408e-01,  3.0488e-01,  2.0502e-01,  2.7582e-01],\n",
       "           [ 3.2571e-01,  2.1097e-01,  2.9043e-01,  2.7779e-01],\n",
       "           [ 2.1525e-01,  8.9779e-02,  6.2128e-02,  1.8182e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 4.6925e-02,  1.9244e-01, -7.9450e-02, -1.2289e-01],\n",
       "           [-3.4451e-01,  2.7347e-01, -5.3977e-02,  1.0407e+00],\n",
       "           [-3.2412e-01,  1.5622e-01, -1.5859e-01,  1.0190e+00],\n",
       "           [-1.1243e-01,  2.0346e-01,  3.8536e-01,  1.5239e-01]],\n",
       " \n",
       "          [[ 6.8130e-02, -1.3792e-01,  2.3011e-01,  4.6194e-01],\n",
       "           [-8.4953e-03, -1.4321e-01,  1.1608e-01,  4.0652e-02],\n",
       "           [ 6.0096e-02,  9.5288e-02, -9.0419e-02,  4.9937e-02],\n",
       "           [ 1.7786e-02, -9.9261e-02, -1.3227e-01, -1.4552e-01]],\n",
       " \n",
       "          [[-3.5596e-02, -2.3193e-02, -4.9852e-01,  4.5538e-01],\n",
       "           [ 2.7055e-01, -1.2702e-01,  2.4700e-01,  7.1085e-01],\n",
       "           [ 1.1312e-01, -2.8751e-01, -3.0371e-01,  2.8479e-01],\n",
       "           [ 2.0236e-01,  1.1883e-01,  1.0682e-01,  1.2397e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.8332e-03, -3.8003e-02,  9.8509e-02,  4.0684e-02],\n",
       "           [-7.3979e-02, -3.6786e-02,  6.3702e-02,  1.0903e-01],\n",
       "           [ 1.1370e-04,  4.9357e-03,  4.7932e-01, -3.2768e-01],\n",
       "           [-9.8715e-02, -1.5723e-01,  2.4218e-02,  6.6511e-02]],\n",
       " \n",
       "          [[ 9.0164e-02,  9.2216e-02,  2.1948e-01,  4.6415e-01],\n",
       "           [ 2.7175e-01,  3.8214e-01,  2.7969e-01,  5.0920e-01],\n",
       "           [ 2.5609e-01,  2.2746e-01,  4.8979e-01,  2.9014e-01],\n",
       "           [ 1.3256e-01,  2.4939e-01,  2.4976e-01,  2.3052e-01]],\n",
       " \n",
       "          [[ 2.6077e-01,  2.3329e-01, -3.5075e-01, -9.1890e-02],\n",
       "           [ 4.4965e-01,  1.9533e-01,  4.7652e-01,  6.2370e-01],\n",
       "           [ 3.6172e-01,  1.4545e-01, -1.8235e-01, -2.9904e-01],\n",
       "           [ 2.5205e-01,  9.1107e-02,  8.5597e-02,  1.7347e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.9500e-01,  1.9534e-01, -4.1665e-01, -4.9488e-01],\n",
       "           [-2.5875e-01,  3.4761e-03,  1.3180e+00,  5.1463e-01],\n",
       "           [-3.2331e-01,  1.6092e-01, -3.3116e-01,  5.9571e-01],\n",
       "           [-1.3016e-01,  3.0501e-01,  4.4678e-01,  2.2588e-01]],\n",
       " \n",
       "          [[ 3.8724e-02, -1.8322e-01,  5.0360e-01,  1.2028e+00],\n",
       "           [ 8.0902e-03, -2.3244e-01, -2.7991e-01, -1.7254e+00],\n",
       "           [-5.1273e-02, -1.5148e-01, -3.2409e-01,  3.9435e-01],\n",
       "           [ 6.8757e-02, -1.2514e-01, -8.1802e-02,  7.6877e-02]],\n",
       " \n",
       "          [[ 1.8913e-01, -3.8629e-01,  3.8975e-01,  6.6705e-02],\n",
       "           [ 5.6570e-02, -2.9245e-01, -7.0156e-01,  3.9353e-01],\n",
       "           [ 1.2813e-01, -5.9540e-02, -7.3006e-02,  6.5637e-01],\n",
       "           [ 1.7234e-01,  1.1913e-01, -6.4367e-02, -5.0928e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.9519e-02,  2.9502e-02, -3.7174e-01, -7.3940e-01],\n",
       "           [ 6.4777e-02,  1.2592e-01, -3.4202e-01, -6.5728e-01],\n",
       "           [ 2.6614e-02, -1.7609e-02, -2.8469e-01, -2.2360e-01],\n",
       "           [-1.1089e-01, -8.0503e-02,  1.1707e-01,  1.2464e-01]],\n",
       " \n",
       "          [[ 1.1394e-02,  1.0423e-01,  9.3120e-01,  4.2826e-01],\n",
       "           [ 2.7078e-01,  4.9812e-01, -2.2470e-01, -3.2362e-01],\n",
       "           [ 1.4397e-01,  2.7452e-01,  8.1297e-01,  2.1958e-02],\n",
       "           [ 1.1685e-01,  1.9709e-01,  7.5124e-02,  1.7364e-01]],\n",
       " \n",
       "          [[ 2.9252e-01,  6.7539e-02,  7.5939e-01,  9.8029e-02],\n",
       "           [ 3.2590e-01,  3.6215e-01,  4.9307e-01,  1.3780e-01],\n",
       "           [ 3.9796e-01,  5.5743e-02, -4.2525e-01,  7.8469e-01],\n",
       "           [ 2.2628e-01,  6.2468e-02, -1.9240e-02, -5.2732e-02]]]],\n",
       "        grad_fn=<NativeBatchNormBackward0>),\n",
       " tensor([[[[ 3.0744e+00,  2.8375e+00,  1.1171e+00,  6.2943e-01],\n",
       "           [-2.4022e+00,  5.4110e+00,  8.2371e-01,  1.3472e-01],\n",
       "           [-4.2339e-01,  3.8943e+00, -3.4603e-01, -2.0256e-02],\n",
       "           [-3.8748e-01, -8.5947e-01,  2.5088e-02,  7.1022e-01]],\n",
       " \n",
       "          [[ 1.4675e+00,  2.3920e+00,  6.5450e+00,  1.8532e+00],\n",
       "           [ 4.7961e-01,  3.8653e+00, -2.6944e-01,  2.2100e+00],\n",
       "           [-8.3251e-01, -3.0424e+00,  5.9721e-01, -2.8162e-01],\n",
       "           [-1.8766e-01, -1.0378e+00,  9.6372e-03, -5.6657e-01]],\n",
       " \n",
       "          [[-4.6170e+00, -1.1016e+00,  2.7686e+00,  3.6273e+00],\n",
       "           [-1.2107e+00, -2.9902e+00,  4.4954e-01,  2.4651e+00],\n",
       "           [-1.5829e-03,  2.4464e-01, -8.9706e-01,  2.3065e+00],\n",
       "           [-4.9249e-01,  1.0275e+00,  1.5224e+00,  1.2723e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.2402e+00,  1.1931e+00,  5.3019e+00,  1.6640e+00],\n",
       "           [ 8.9868e-01,  3.9879e-01,  2.5959e+00, -4.4956e+00],\n",
       "           [-8.9103e-01, -1.2670e+00, -3.6385e-01, -2.5946e+00],\n",
       "           [-3.3596e-01,  2.9816e-01,  1.2053e+00,  2.5094e-01]],\n",
       " \n",
       "          [[-4.8346e-02,  3.5010e+00, -4.8767e+00, -1.9247e+00],\n",
       "           [-2.4412e+00, -2.8009e-01,  2.7115e+00, -1.4536e-02],\n",
       "           [-8.2771e-01, -2.0714e-01,  2.4050e-01,  1.5068e+00],\n",
       "           [ 4.6255e-01,  5.3337e-01, -8.6392e-01,  3.4840e-01]],\n",
       " \n",
       "          [[ 1.2983e+00,  6.5009e+00,  2.5153e+00, -2.3521e+00],\n",
       "           [-1.1685e+00,  2.2346e+00,  4.0764e-01, -1.1836e-01],\n",
       "           [-3.3171e+00,  1.4135e+00, -5.5993e-01,  9.9532e-01],\n",
       "           [ 1.3711e-01, -1.4037e+00, -4.5941e-01,  1.9113e+00]]],\n",
       " \n",
       " \n",
       "         [[[-1.7268e-01, -4.5300e-02, -7.4537e-02,  5.3324e-02],\n",
       "           [-3.9475e-02,  1.1420e-01,  8.1310e-02, -2.9209e-01],\n",
       "           [-3.5184e-01,  1.7695e-01,  2.8726e-01, -2.5291e-01],\n",
       "           [-2.3877e-01,  5.1546e-02, -7.8996e-02,  4.4664e-02]],\n",
       " \n",
       "          [[-1.3165e-01, -2.0684e-01, -3.7808e-01, -1.3760e-01],\n",
       "           [-1.8227e-01, -4.0889e-02, -2.7548e-01, -3.0512e-01],\n",
       "           [-9.2144e-03, -4.3768e-01,  7.0137e-02, -1.0322e-01],\n",
       "           [-6.8358e-02, -8.0716e-02, -2.0476e-01, -4.3377e-02]],\n",
       " \n",
       "          [[ 3.4479e-01, -5.7976e-01,  1.7121e-01,  3.1782e-01],\n",
       "           [-2.1931e-01, -5.2372e-01, -4.0210e-01, -6.3180e-01],\n",
       "           [ 1.3992e-01, -2.8791e-01, -1.3316e-01, -5.2911e-01],\n",
       "           [ 5.9389e-02,  4.3606e-02,  3.5783e-02, -2.2009e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.5339e-01,  1.8704e-01, -2.5034e-01, -1.6932e-03],\n",
       "           [-6.3428e-02, -2.1792e-01, -1.8961e-01,  2.5867e-01],\n",
       "           [-2.2495e-01, -1.4897e-01, -1.9550e-01,  1.6492e-01],\n",
       "           [-2.3611e-01, -1.1625e-01,  3.6262e-02,  1.9664e-01]],\n",
       " \n",
       "          [[-4.0855e-01, -2.5736e-01, -7.5230e-02,  1.0635e-01],\n",
       "           [-9.3766e-02, -2.5271e-01, -1.0597e-01, -2.6647e-01],\n",
       "           [ 1.6111e-01, -7.9740e-02,  5.4838e-01, -1.6252e-01],\n",
       "           [ 5.2986e-02, -1.4818e-01, -1.5276e-01, -2.3630e-01]],\n",
       " \n",
       "          [[-1.6143e-01, -4.4719e-01, -2.5928e-01, -8.1947e-02],\n",
       "           [-1.0771e-01,  1.7319e-01,  1.3580e-01, -3.0768e-01],\n",
       "           [-2.2227e-03,  2.3901e-01,  3.8895e-01,  2.4959e-01],\n",
       "           [ 1.5849e-01,  5.1366e-01,  3.7406e-01,  1.8418e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 3.0857e-01, -5.2814e-01, -2.0176e-01, -3.8007e-01],\n",
       "           [-3.8536e-01, -5.0267e-01, -5.6135e-01,  7.7447e-01],\n",
       "           [-4.1860e-02,  3.8679e-02,  1.6048e-01, -4.8609e-01],\n",
       "           [-1.6531e-01, -5.6854e-02,  2.3385e-01, -9.7425e-02]],\n",
       " \n",
       "          [[-2.5171e-01,  1.8505e-01,  6.3079e-02, -1.9309e-01],\n",
       "           [ 5.9082e-02, -1.5186e-01, -1.8984e-01, -5.2760e-01],\n",
       "           [ 2.8954e-03,  3.2182e-02,  3.2110e-01, -2.4818e-01],\n",
       "           [-8.3455e-02, -1.2297e-01, -1.4994e-01, -7.3624e-02]],\n",
       " \n",
       "          [[ 3.8598e-01,  1.0182e-01,  3.1606e-01,  8.6377e-01],\n",
       "           [ 3.8172e-01, -1.0252e+00, -1.0438e+00, -5.4065e-01],\n",
       "           [ 5.4667e-01, -1.0538e+00, -7.1639e-01,  4.3226e-01],\n",
       "           [ 3.7949e-01,  1.1323e-01, -1.2339e-01, -1.0403e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.2392e-01, -1.4755e-01,  9.1687e-01,  8.4791e-01],\n",
       "           [-3.2781e-01, -2.0523e-01, -5.7599e-02, -1.5934e-01],\n",
       "           [-4.3365e-01, -2.4483e-01, -2.3064e-01,  5.9233e-01],\n",
       "           [-9.2624e-02, -1.2581e-01, -2.0753e-01,  2.5565e-01]],\n",
       " \n",
       "          [[-3.9060e-01, -3.5686e-01,  2.5039e-01,  1.3484e+00],\n",
       "           [-4.9165e-01,  1.5330e-01,  6.5151e-01, -2.3758e-01],\n",
       "           [-9.5681e-02, -3.0406e-01,  4.3010e-01,  3.9675e-01],\n",
       "           [-5.4565e-04,  1.6327e-02, -6.5730e-02,  7.7773e-03]],\n",
       " \n",
       "          [[-1.8813e-01, -3.1475e-01, -1.2542e+00,  7.7445e-01],\n",
       "           [-1.4966e-01, -3.2159e-01, -8.3762e-01, -8.6166e-01],\n",
       "           [ 7.6760e-02,  3.8774e-01,  2.8828e-01,  1.0312e+00],\n",
       "           [ 1.5989e-01,  1.8523e-01,  4.3230e-01,  3.4156e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.3442e-01,  3.2373e-01, -3.6645e-01, -3.6009e-02],\n",
       "           [-2.2652e-01,  1.2634e-01, -6.2858e-02, -1.4728e-01],\n",
       "           [-2.2350e-01,  2.0561e-01, -7.9416e-02,  3.4331e-01],\n",
       "           [-2.6630e-01,  4.3686e-02, -7.1555e-02,  7.8764e-02]],\n",
       " \n",
       "          [[-2.0269e-01, -4.0325e-01, -1.7346e-01, -1.1350e-01],\n",
       "           [ 9.1791e-03, -3.9413e-01,  9.8974e-02, -2.4600e-02],\n",
       "           [-6.3727e-02, -7.6942e-02, -1.4594e-01, -7.2583e-02],\n",
       "           [-1.1504e-01, -1.4658e-01, -2.3262e-01, -1.5546e-02]],\n",
       " \n",
       "          [[ 1.7089e-01, -4.7784e-02, -2.9147e-01, -2.9231e-02],\n",
       "           [ 1.8636e-01, -4.2337e-01,  2.3978e-02,  4.5639e-02],\n",
       "           [ 1.8633e-01, -1.4974e-01, -2.6474e-01, -3.0450e-01],\n",
       "           [ 1.4461e-01,  9.2556e-02, -1.5143e-01, -1.1835e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.6380e-01, -1.4798e-01, -1.2467e-02,  2.1180e-01],\n",
       "           [-4.1695e-01, -2.9334e-01, -1.3290e-01,  1.5628e-01],\n",
       "           [-2.9621e-01, -3.7979e-01, -1.4124e-01,  5.9597e-02],\n",
       "           [-2.5092e-01, -1.0077e-01,  3.8339e-02,  2.8163e-01]],\n",
       " \n",
       "          [[-1.2185e-01,  8.3150e-02,  1.8443e-01, -3.4827e-02],\n",
       "           [-2.3852e-01,  2.4358e-03,  2.5838e-01,  1.8270e-02],\n",
       "           [-1.0418e-01,  5.9946e-02,  3.8919e-01, -1.7890e-03],\n",
       "           [ 2.4452e-02, -4.6301e-02, -5.8500e-02, -1.9842e-01]],\n",
       " \n",
       "          [[-5.4282e-02, -2.7241e-01, -1.7894e-01, -2.2389e-01],\n",
       "           [-1.3417e-01,  3.8724e-02, -3.1698e-01,  5.5588e-02],\n",
       "           [-2.6770e-03,  5.0625e-01,  2.3344e-01,  1.5752e-01],\n",
       "           [ 1.5590e-01,  5.5082e-01,  3.9269e-01,  3.0079e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.1185e-01,  1.2624e-01, -9.4109e-01,  8.8510e-01],\n",
       "           [-2.1390e-01, -3.9089e-02, -3.0902e-01, -1.1136e+00],\n",
       "           [-3.3694e-01,  1.3011e-01,  8.7910e-02,  1.3672e-01],\n",
       "           [-3.6460e-01,  1.9074e-01, -2.7077e-01, -1.9604e-01]],\n",
       " \n",
       "          [[-1.9805e-01,  8.0989e-02, -8.0742e-01,  4.5972e-02],\n",
       "           [ 1.5136e-01, -1.5442e-01, -1.4108e-01,  7.1972e-02],\n",
       "           [ 1.9921e-02, -4.7416e-01, -1.4088e-01,  4.5394e-01],\n",
       "           [-9.5488e-02, -6.3535e-03,  2.7920e-02, -1.7085e-01]],\n",
       " \n",
       "          [[ 1.9710e-01, -6.5756e-02,  7.0732e-01, -3.1968e-01],\n",
       "           [ 3.0589e-01, -4.8270e-01, -1.5334e+00,  4.2382e-01],\n",
       "           [ 1.4481e-01, -1.9364e-01, -1.1823e+00, -1.1074e+00],\n",
       "           [ 1.1337e-01,  1.0594e-01,  1.6228e-01, -1.7365e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.4124e-01, -9.0786e-02, -6.1952e-01,  8.2126e-02],\n",
       "           [-2.9786e-01, -1.6812e-01,  2.1320e-01,  2.7041e-01],\n",
       "           [-3.3033e-01, -1.9335e-01,  6.0310e-01,  1.2024e+00],\n",
       "           [-2.5911e-01, -2.2556e-01, -2.8379e-01,  2.2129e-01]],\n",
       " \n",
       "          [[-3.5498e-01, -1.3715e-01,  9.0255e-01, -1.1484e-01],\n",
       "           [-4.9938e-02, -1.7752e-01,  1.1806e-01, -6.1643e-01],\n",
       "           [-2.1467e-01,  1.7390e-01,  9.3914e-01, -2.9530e-01],\n",
       "           [ 4.4979e-02, -1.9773e-01,  7.0818e-02, -9.6695e-02]],\n",
       " \n",
       "          [[-1.8690e-01, -9.3447e-02,  4.6768e-01,  1.3986e-01],\n",
       "           [-1.3419e-02, -3.7521e-01, -9.5557e-01, -1.5102e+00],\n",
       "           [-8.1745e-03,  2.9192e-01, -6.5845e-01, -7.2723e-01],\n",
       "           [ 9.4234e-02,  4.4308e-01,  1.1886e-01,  5.3283e-01]]],\n",
       " \n",
       " \n",
       "         [[[-8.6720e-02, -9.0614e-02,  1.9182e+00, -3.5572e-02],\n",
       "           [-9.2501e-02,  4.6069e-02, -8.1581e-01,  3.5889e-01],\n",
       "           [-3.5375e-01,  8.4759e-02,  7.0215e-01, -3.9163e-01],\n",
       "           [-3.1658e-01,  1.7041e-01, -4.9304e-01, -3.0933e-01]],\n",
       " \n",
       "          [[-3.5657e-01, -1.4219e-01, -9.3512e-01, -8.1913e-02],\n",
       "           [ 1.5450e-01, -2.2723e-01, -2.9214e-01, -1.3249e+00],\n",
       "           [-7.7833e-03, -1.1909e-01,  4.0412e-01, -2.0491e-01],\n",
       "           [-8.9872e-02, -1.4361e-01, -2.7138e-01, -1.2254e-01]],\n",
       " \n",
       "          [[ 7.7662e-02, -6.5085e-03, -8.6629e-01,  2.2275e+00],\n",
       "           [-2.5645e-01,  2.0368e-02,  1.8387e-01,  1.4198e-01],\n",
       "           [ 1.9061e-01, -3.3459e-01, -1.9692e+00,  5.1792e-01],\n",
       "           [ 6.2928e-02, -3.1103e-02, -2.9415e-01, -6.6722e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3967e-02, -5.5007e-02,  1.2615e+00,  1.1365e+00],\n",
       "           [-3.2643e-01, -2.6109e-01,  5.1911e-01, -4.8604e-01],\n",
       "           [-3.1867e-01, -1.5149e-01,  4.3259e-01,  1.3849e+00],\n",
       "           [-2.3939e-01, -1.1688e-01,  1.1673e-01,  2.5160e-01]],\n",
       " \n",
       "          [[-1.9405e-01, -1.5030e-02, -8.9660e-01,  4.0800e-01],\n",
       "           [-5.2467e-01,  8.3261e-02, -6.7613e-01,  1.9103e+00],\n",
       "           [-8.2966e-02, -1.6324e-01,  1.7664e-02,  8.0051e-01],\n",
       "           [ 4.5962e-02, -6.0863e-02, -4.7218e-02,  5.5587e-02]],\n",
       " \n",
       "          [[-4.7556e-02, -4.9594e-01,  8.4265e-01,  1.7076e+00],\n",
       "           [-2.2374e-01,  3.6120e-01, -1.5982e+00, -1.8385e+00],\n",
       "           [-1.5511e-01,  4.1109e-01, -1.0871e+00, -1.9856e-02],\n",
       "           [ 1.6886e-01,  3.7063e-01,  3.9651e-01, -2.6439e-01]]]],\n",
       "        grad_fn=<NativeBatchNormBackward0>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = [32, 64, 128, 256, 64, 2]\n",
    "out_channels = [32, 64, 128, 256, 64, 256]\n",
    "\n",
    "# shapes = [1,4,8,16,32]\n",
    "# out_shapes = [1,4,8,16,32]\n",
    "shapes = [1,4,4,4,4]\n",
    "#out_shapes = [1,4,4]\n",
    "out_shapes = [4,4,4,4,4]\n",
    "abfs = nn.ModuleList()\n",
    "mid_channel = min(512, in_channels[-1])\n",
    "for idx, in_channel in enumerate(in_channels):\n",
    "    abfs.append(ABF(in_channel, mid_channel, out_channels[idx], idx < len(in_channels)-1))\n",
    "abfs = abfs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [2, 2, 1, 1], expected input[8, 256, 4, 483] to have 2 channels, but got 256 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m x \u001b[39m=\u001b[39m feature_maps[\u001b[39m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m out_features, res_features \u001b[39m=\u001b[39m abfs[\u001b[39m0\u001b[39;49m](x, out_shape\u001b[39m=\u001b[39;49mout_shapes[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      6\u001b[0m results\u001b[39m.\u001b[39mappend(out_features)\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m abf, shape, out_shape \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(abfs[:\u001b[39m1\u001b[39m], shapes[:\u001b[39m1\u001b[39m], out_shapes[:\u001b[39m1\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/NTH_student/Speech_Enhancement_new/knowledge_distillation_CLSKD/framework.py:200\u001b[0m, in \u001b[0;36mABF.forward\u001b[0;34m(self, x, y, shape, out_shape)\u001b[0m\n\u001b[1;32m    198\u001b[0m n,_,h,w \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m    199\u001b[0m \u001b[39m# transform student features\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matt_conv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[39m# upsample residual features\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(y, (shape,shape\u001b[39m+\u001b[39m\u001b[39m479\u001b[39m), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [2, 2, 1, 1], expected input[8, 256, 4, 483] to have 2 channels, but got 256 channels instead"
     ]
    }
   ],
   "source": [
    "student_features = model(X,is_feat=True)\n",
    "logit = student_features[0]\n",
    "x = feature_maps[2]\n",
    "results = []\n",
    "out_features, res_features = abfs[0](x, out_shape=out_shapes[0])\n",
    "results.append(out_features)\n",
    "for abf, shape, out_shape in zip(abfs[:1], shapes[:1], out_shapes[:1]):\n",
    "        out_features, res_features = abf(x, res_features, shape, out_shape)\n",
    "        results.insert(0, out_features)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 256, 4])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 256, 4])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 512])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 512])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
